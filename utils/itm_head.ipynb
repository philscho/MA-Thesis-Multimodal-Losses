{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "rootutils.setup_root('.', indicator=\".project-root\", pythonpath=True)\n",
    "from src.model.model_module import LitMML\n",
    "from src.model.utils import get_model_and_processor\n",
    "from omegaconf import OmegaConf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phisch/venv_py3.8/py3.8/lib/python3.8/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.2.3, which is newer than your current Lightning version: v2.2.0.post0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = '/data/bhavin/ckpts_old/93t3xgrr/ckpt-epoch=14-loss-val=2.208.ckpt' # CLIP+ITM\n",
    "model, processor = get_model_and_processor(config=OmegaConf.load('configs/model/dual_encoder.yaml'))\n",
    "lit_model = LitMML.load_from_checkpoint(ckpt_path, model=model, processor=processor)\n",
    "model, processor = lit_model.model, lit_model.processor\n",
    "itm_head = lit_model.itm_head\n",
    "print(itm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_itm_head_predictions(itm_head, sim_f2t, top_k, features, classifier):\n",
    "    batch_size = sim_f2t.shape[0]\n",
    "    if sim_f2t.size(-1) < top_k:\n",
    "        top_k = sim_f2t.size(-1)\n",
    "    _, top_indices = torch.topk(sim_f2t, top_k, dim=-1)\n",
    "    topk_class_embeds = torch.stack(\n",
    "        [torch.index_select(classifier, dim=1, index=top_indices[i, :]).T for i in range(batch_size)]\n",
    "    )\n",
    "    multimodal_embeddings = torch.cat(\n",
    "        [features.unsqueeze(1).expand(-1, top_k, -1), topk_class_embeds], dim=-1\n",
    "    ).to(torch.float32)\n",
    "    logits = itm_head(multimodal_embeddings)\n",
    "    matching_logits = logits[:, :, 0]\n",
    "    mask = torch.full_like(sim_f2t, fill_value=False, dtype=torch.bool)\n",
    "    for i in range(sim_f2t.size(0)):\n",
    "        mask[i, top_indices[i]] = True\n",
    "    sim_f2t.fill_(-float('inf'))\n",
    "    sim_f2t[mask] = matching_logits.flatten()  # Replace with new values (example)\n",
    "    return sim_f2t\n",
    "    # indices_max_class_logits = torch.argmax(logits[:, :, 0], dim=-1)\n",
    "    # pred_classes = torch.gather(top_indices, dim=1, index=indices_max_class_logits.unsqueeze(-1))\n",
    "    # return pred_classes.squeeze(-1).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    -inf, -35.7969,     -inf,     -inf,     -inf,     -inf, -42.8828,\n",
      "         -28.3120, -36.1812, -42.7253],\n",
      "        [    -inf, -47.6826, -42.3259, -27.8318,     -inf,     -inf,     -inf,\n",
      "         -53.4408, -41.4452,     -inf],\n",
      "        [    -inf, -33.8399,     -inf,     -inf,     -inf, -60.0919, -42.9712,\n",
      "         -60.3185,     -inf, -41.3794],\n",
      "        [    -inf, -38.6740, -42.6128,     -inf,     -inf, -46.7317,     -inf,\n",
      "             -inf, -45.3212, -39.5793],\n",
      "        [-39.3563,     -inf, -34.7509,     -inf, -40.4056,     -inf, -38.3079,\n",
      "         -24.8190,     -inf,     -inf],\n",
      "        [-34.2702, -28.2009,     -inf,     -inf,     -inf, -42.9782, -52.2685,\n",
      "             -inf, -51.5873,     -inf],\n",
      "        [-45.7405, -46.6931,     -inf,     -inf,     -inf,     -inf,     -inf,\n",
      "         -45.3044, -62.2246, -50.2090],\n",
      "        [-57.9832,     -inf,     -inf,     -inf, -40.5351, -39.3979, -40.2696,\n",
      "         -42.7699,     -inf,     -inf]], device='cuda:0',\n",
      "       grad_fn=<IndexPutBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "sim_f2t = torch.randn(8, 10).to(device)\n",
    "top_k = 5\n",
    "features = torch.randn(8, 512).to(device)\n",
    "classifier = torch.randn(512, 10).to(device)\n",
    "preds = _get_itm_head_predictions(itm_head, sim_f2t, top_k, features, classifier)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0731, 0.9269]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[-63.8308,  58.4294],\n",
    "        [-48.5656,  45.5814],\n",
    "        [-53.5590,  48.5309],\n",
    "        [-19.3385,  13.9102],\n",
    "        [-63.9262,  59.6700],\n",
    "        [-43.9359,  36.5553]])\n",
    "\n",
    "softmax = torch.nn.LogSoftmax(dim=1)\n",
    "log_probs = torch.softmax(torch.tensor([[-1.39,  1.15]]), 1)\n",
    "print(log_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
