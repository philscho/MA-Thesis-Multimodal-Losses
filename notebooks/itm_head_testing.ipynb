{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "rootutils.setup_root('../', indicator=\".project-root\", pythonpath=True)\n",
    "from src.model.model_module import LitMML\n",
    "from src.model.utils import get_model_and_processor\n",
    "from omegaconf import OmegaConf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phisch/venv_py3.8/py3.8/lib/python3.8/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.2.3, which is newer than your current Lightning version: v2.2.0.post0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = '/data/bhavin/ckpts/93t3xgrr/ckpt-epoch=14-loss-val=2.208.ckpt' # CLIP+ITM\n",
    "model, processor = get_model_and_processor(config=OmegaConf.load('../configs/model/dual_encoder.yaml'))\n",
    "lit_model = LitMML.load_from_checkpoint(ckpt_path, model=model, processor=processor)\n",
    "model, processor = lit_model.model, lit_model.processor\n",
    "itm_head = lit_model.itm_head\n",
    "print(itm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[-0.7769, -0.4848,  0.2617,  ..., -0.1786, -1.3835,  0.7025],\n",
      "        [-1.0671, -1.0295, -0.5723,  ..., -0.0891, -2.1650,  0.7870],\n",
      "        [-0.3240, -0.5818,  0.9855,  ...,  1.6382,  0.6030,  1.1252],\n",
      "        [ 0.8481,  1.1996,  0.1406,  ...,  0.2321, -0.0255,  1.4783]],\n",
      "       device='cuda:0')\n",
      "Output:\n",
      "tensor([[-51.1446,  50.4647],\n",
      "        [-48.0244,  46.4656],\n",
      "        [-33.9451,  33.9389],\n",
      "        [-43.4788,  42.4063]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.randn(4, 1024).to('cuda')\n",
    "print(\"Input:\")\n",
    "print(random_tensor)\n",
    "print(\"Output:\")\n",
    "print(itm_head(random_tensor))\n",
    "# Logit 0: match, logit 1: no match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Caltech101': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7bd9821fd0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d2b0>}, 'Caltech256': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d3d0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d4c0>}, 'CIFAR10': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d5b0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d6a0>}, 'CIFAR100': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d790>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d880>}, 'DTD': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81d970>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81da60>}, 'FGVCAircraft': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81db50>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81dc40>}, 'Food101': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81dd30>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81de20>}, 'OxfordIIITPet': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d81df10>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d826040>}, 'StanfordCars': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d826130>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d826220>}, 'STL10': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d826310>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7a5d826400>}}\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_module import MyDataModule\n",
    "data_config = OmegaConf.load('../configs/data/test.yaml')\n",
    "data_config.root = '/home/data'\n",
    "data_config.dataloader.test.batch_size = 16\n",
    "data_module = MyDataModule(data_config=data_config, processor=processor)\n",
    "dataloaders = data_module.get_test_dataloaders()\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing output of ITM head for one batch of images with same label template caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_caltech101 = dataloaders['Caltech101']['test']\n",
    "batch = next(iter(loader_caltech101))\n",
    "inputs, targets = batch\n",
    "print(inputs.shape)\n",
    "print(inputs)\n",
    "print(targets.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.get_image_features(inputs.to('cuda'))\n",
    "print(features.shape)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Faces', 'Faces', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car side', 'ceiling fan', 'cellphone', 'chair', 'chandelier', 'cougar body', 'cougar face', 'crab', 'crayfish', 'crocodile', 'crocodile head', 'cup', 'dalmatian', 'dollar bill', 'dolphin', 'dragonfly', 'electric guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo head', 'garfield', 'gerenuk', 'gramophone', 'grand piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline skate', 'joshua tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea horse', 'snoopy', 'soccer ball', 'stapler', 'starfish', 'stegosaurus', 'stop sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water lilly', 'wheelchair', 'wild cat', 'windsor chair', 'wrench', 'yin yang']\n"
     ]
    }
   ],
   "source": [
    "classnames = loader_caltech101.dataset.classnames\n",
    "print(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a photo of a dolphin.\n"
     ]
    }
   ],
   "source": [
    "template = \"a photo of a {}.\"\n",
    "caption = template.format(classnames[33])\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1037,  6302,  1997,  1037, 17801,  1012,   102]])\n"
     ]
    }
   ],
   "source": [
    "caption_tokenized = processor(text=caption, padding=True, truncation=True, return_tensors=\"pt\")['input_ids']\n",
    "print(caption_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "tensor([[ 3.6345e-01, -9.5647e-02,  2.1639e-01, -6.4779e-01, -5.5535e-02,\n",
      "          8.6517e-01,  7.8397e-01, -2.0864e-01, -1.1221e+00,  1.2738e+00,\n",
      "          1.8853e+00,  2.2195e+00, -1.4295e-02, -1.2201e+00, -4.1211e-01,\n",
      "          1.2364e+00,  5.6074e-01, -1.1828e+00, -6.3703e-01, -1.3100e+00,\n",
      "         -1.0932e+00, -2.8891e-01, -1.1838e-01, -1.2127e-02,  2.3077e-01,\n",
      "          6.1105e-02,  2.3475e-01, -1.6820e+00, -3.5458e-01, -5.6923e-02,\n",
      "         -1.3380e+00,  1.0484e+00, -2.7518e-01, -4.9735e-01, -1.3581e-01,\n",
      "          5.7183e-01,  1.2141e+00,  4.4431e-01,  1.4220e+00, -1.3342e+00,\n",
      "         -3.0494e-01,  2.2135e-01, -8.9773e-02, -6.7024e-01, -7.0473e-01,\n",
      "         -5.5582e-01, -1.5082e-01,  5.0931e-01,  3.6776e-01, -8.2197e-01,\n",
      "         -1.0181e+00,  2.8512e-01,  3.1793e-01,  1.3616e+00, -1.4496e+00,\n",
      "          3.7434e-01,  5.4244e-01, -4.7219e-01,  1.1753e+00, -6.1422e-01,\n",
      "          1.3694e+00,  5.7788e-01,  8.1777e-01, -1.0191e+00,  1.5862e+00,\n",
      "         -8.8899e-02,  1.0649e+00,  1.6027e-01,  2.5721e-01,  3.3665e-01,\n",
      "         -7.3902e-01, -1.5878e+00, -6.3955e-01,  1.4405e+00,  4.8797e-01,\n",
      "          9.3166e-01, -1.5146e+00, -1.6009e+00,  8.7258e-01, -1.1366e+00,\n",
      "         -3.4818e-01, -5.6273e-01, -1.5018e+00,  4.5163e-01,  6.5464e-01,\n",
      "          3.6389e-01,  1.1838e+00,  6.8606e-01, -1.6209e+00,  3.3247e-01,\n",
      "          7.8498e-01, -5.7479e-01,  2.4195e-01, -1.2545e+00,  1.4078e+00,\n",
      "         -1.1841e+00, -1.5680e-01, -1.9468e-01, -1.8847e+00, -5.7552e-01,\n",
      "          9.4190e-02,  1.1815e-01, -7.0337e-01,  2.1359e-01,  9.4986e-01,\n",
      "          4.4186e-01, -2.5771e-01, -2.1389e-01,  6.6246e-02,  1.8753e+00,\n",
      "         -2.2294e-01,  5.5654e-01, -2.4196e-01,  4.2536e-02,  8.5734e-01,\n",
      "          4.8191e-01, -4.2028e-01,  6.6075e-02,  1.0658e+00, -7.2686e-02,\n",
      "         -6.7650e-02, -4.9605e-01, -3.5004e-02,  4.2338e-01,  1.6262e+00,\n",
      "         -1.3277e+00, -1.4867e-01,  8.1819e-01,  2.8257e-01, -1.5922e+00,\n",
      "         -4.2194e-02,  1.4105e-01,  1.8160e-01,  1.7842e+00,  1.3061e+00,\n",
      "         -5.3476e-01,  4.9987e-01, -7.1475e-01, -8.0019e-01,  1.7050e+00,\n",
      "         -6.6306e-02,  3.2294e-01, -1.9890e-01,  6.5448e-01, -7.6303e-01,\n",
      "          3.8323e-01, -7.7404e-02, -9.3289e-01,  3.2761e-01, -9.6887e-01,\n",
      "         -6.1441e-01, -2.3426e-01, -6.3016e-02, -1.4268e+00,  2.9962e-01,\n",
      "         -3.1798e-01,  4.4335e-01,  2.1597e-01,  7.5851e-01,  3.0151e-01,\n",
      "         -1.3932e+00,  1.6107e-01, -2.3709e-01,  1.9186e+00, -1.8737e-01,\n",
      "          1.5257e+00,  4.2771e-01, -5.1363e-02,  2.9477e-01,  5.5081e-01,\n",
      "         -6.2620e-01, -8.0039e-01, -2.1748e+00,  1.4421e+00, -1.1089e+00,\n",
      "         -5.4188e-01, -1.2781e+00, -4.8273e-01,  1.4859e+00,  1.5328e+00,\n",
      "          6.5098e-01, -8.2306e-01, -5.3764e-01,  2.1684e-01, -5.8288e-01,\n",
      "          8.9199e-01, -8.6866e-01,  1.0433e+00,  1.6684e+00,  1.9886e-01,\n",
      "          2.7060e-01,  4.6957e-01, -1.5398e+00, -7.4444e-01,  4.8842e-01,\n",
      "          1.1755e+00,  8.2970e-01, -4.7586e-01, -9.1840e-02, -1.4472e-01,\n",
      "         -7.9966e-01, -2.0094e+00, -1.3121e+00, -9.2093e-01,  2.3502e+00,\n",
      "         -1.2828e+00, -6.1284e-01,  7.0798e-01,  2.7878e-01,  2.5646e-01,\n",
      "          1.5503e-01, -5.4741e-02,  1.7568e-01, -1.6328e+00, -5.4598e-01,\n",
      "          2.2838e+00, -6.7979e-01, -2.2574e-01, -1.5362e+00, -9.6539e-02,\n",
      "         -5.1216e-01,  1.3675e+00,  6.3909e-01,  1.6132e+00,  1.1624e+00,\n",
      "          7.5283e-01, -5.5121e-04, -1.8114e+00,  2.5598e-01,  1.2936e+00,\n",
      "         -5.0988e-01,  6.6955e-02, -3.2029e-01,  5.9468e-03,  9.9129e-01,\n",
      "         -7.0804e-01, -1.2519e-01, -1.0367e+00,  8.7985e-01, -4.0182e-01,\n",
      "         -6.4004e-01,  1.6771e-02, -1.0335e+00,  4.3187e-01,  1.2545e+00,\n",
      "          3.2600e-01,  1.7457e+00, -7.0149e-01,  5.2596e-02,  3.2855e-02,\n",
      "         -8.4420e-01,  9.0409e-01, -2.0159e-01,  1.3765e-02,  1.1851e+00,\n",
      "          6.2167e-01, -9.9116e-02,  3.8322e-01, -3.7699e-01,  2.7480e-01,\n",
      "         -2.6171e-01, -1.4928e+00,  1.4477e-01, -1.5513e+00, -4.0280e-01,\n",
      "          1.3581e+00,  1.4231e-01, -2.2317e+00,  1.8506e+00,  1.0128e+00,\n",
      "          2.7193e-01,  3.3890e-01,  3.9498e-01,  2.6123e-01,  2.7340e-01,\n",
      "          2.5234e-01,  4.1822e-01,  2.5339e+00,  1.5253e-01,  4.5078e-01,\n",
      "          5.9353e-01,  4.8011e-01,  6.0603e-01, -5.0220e-02,  1.6554e+00,\n",
      "          1.8379e-01, -1.5489e+00,  3.0564e-01,  2.8348e-01,  9.9814e-01,\n",
      "         -1.0397e+00,  5.7425e-01, -1.1630e+00, -5.1901e-01,  1.1599e+00,\n",
      "          6.0684e-01, -1.9220e-02, -7.3351e-01,  1.5813e-01,  3.0785e-01,\n",
      "         -2.1435e+00, -9.4517e-01, -5.7380e-01,  1.0968e+00,  9.4682e-01,\n",
      "          9.9851e-01,  7.9003e-01, -6.4289e-01,  1.2113e+00, -1.7655e+00,\n",
      "          5.6464e-02, -3.2293e-01, -5.0760e-01, -4.8228e-01, -4.5835e-01,\n",
      "          1.0442e+00, -1.9161e+00, -2.9989e-01, -1.5009e-01, -5.1380e-01,\n",
      "          5.1403e-01, -5.5348e-01,  6.0826e-01,  3.5893e-01,  9.1783e-01,\n",
      "          5.6649e-01, -6.6796e-01, -7.3241e-01,  1.1525e+00, -7.1512e-01,\n",
      "         -4.6865e-03, -3.3445e-01,  8.7722e-01, -1.1368e-01, -2.7446e-01,\n",
      "         -2.6927e-01,  5.4036e-01,  2.3397e-01,  3.5313e-01,  4.6388e-01,\n",
      "          8.0663e-01, -2.7522e-01, -1.8182e+00,  1.4183e+00, -8.9790e-01,\n",
      "          1.3345e-01, -6.9418e-01, -1.0028e+00, -1.4807e-01, -9.9228e-02,\n",
      "         -3.0885e-01,  5.8426e-01, -5.3268e-01,  6.1339e-01, -1.6736e-01,\n",
      "          2.1119e-01, -2.4853e-01, -7.0207e-02,  1.2858e+00, -8.4169e-01,\n",
      "         -2.4033e-01,  1.6535e+00,  8.8113e-01,  6.5263e-01, -1.1051e-01,\n",
      "          2.3665e+00,  9.9509e-02,  1.5461e-01,  5.0107e-01, -3.2893e-01,\n",
      "          8.2113e-01,  1.1283e+00, -1.4580e-01, -8.1965e-01,  2.7396e-01,\n",
      "         -7.3423e-03, -7.9171e-02,  6.3033e-01,  5.1726e-01, -1.8109e+00,\n",
      "         -1.5510e+00,  1.0360e+00, -7.4228e-01,  4.9136e-01, -1.3507e-01,\n",
      "          2.5129e-01,  8.5862e-02, -5.7604e-01, -4.1908e-01,  4.4834e-01,\n",
      "         -3.1893e-01,  7.4509e-01,  6.5594e-01,  1.4045e-01,  4.3096e-01,\n",
      "          1.1790e+00,  9.5146e-01,  1.8836e-02, -2.4998e-01, -2.4696e-01,\n",
      "         -6.6346e-01,  1.3383e+00,  5.1924e-01,  7.9049e-03, -2.7234e-01,\n",
      "         -2.2424e+00, -4.1512e-01,  3.4424e-01, -2.4922e-01,  1.3362e-01,\n",
      "         -1.2165e+00, -7.0781e-01, -3.0024e-01,  7.0574e-01,  1.4028e+00,\n",
      "          7.3687e-01, -1.3959e+00,  7.9352e-01,  5.2648e-01,  1.2119e+00,\n",
      "          5.8558e-02,  1.1730e+00, -1.4569e+00,  2.3697e-01,  3.3117e-01,\n",
      "          1.0080e-01, -3.3904e-01, -2.9377e-02,  9.1593e-02,  9.8086e-03,\n",
      "          1.2284e+00,  7.0846e-01,  2.1298e-01,  5.7874e-01,  1.6044e-01,\n",
      "          5.3226e-02,  3.0236e-01,  1.1956e+00, -2.2619e-01,  2.3796e-01,\n",
      "          1.6930e+00, -1.3755e+00,  9.8052e-01,  1.3144e+00, -3.7777e-01,\n",
      "          6.3396e-01,  1.0305e+00,  1.6727e+00,  4.7702e-01, -7.6124e-01,\n",
      "          1.6172e-01, -7.3331e-01, -3.3688e-01,  2.8864e-01, -1.3464e+00,\n",
      "         -4.1751e-01,  8.6655e-01,  1.0434e+00, -6.5398e-01, -2.5016e-02,\n",
      "         -1.9376e+00,  4.4059e-02, -7.9309e-01,  3.0180e-01,  1.1261e+00,\n",
      "          6.6725e-01,  5.7826e-01,  1.8674e-01,  8.4881e-01,  8.2101e-01,\n",
      "         -1.0214e+00, -1.3990e-01,  2.2280e+00,  3.3443e-01, -4.6432e-01,\n",
      "         -8.2386e-01,  2.6786e-01, -3.7356e-01,  4.9447e-01, -6.9374e-01,\n",
      "         -2.1308e-02, -8.8448e-01, -8.6973e-01, -2.3813e-02,  3.1269e-01,\n",
      "         -1.3210e+00,  5.9665e-01, -9.5965e-01, -8.4230e-01,  9.7768e-01,\n",
      "         -2.1162e+00, -1.0995e+00,  1.2656e+00,  6.0661e-01, -3.3525e-01,\n",
      "         -6.2474e-01,  6.7677e-01,  6.3293e-02, -3.4091e-02,  8.1536e-01,\n",
      "         -1.3248e-01,  3.5518e-01,  1.6688e-01,  4.8209e-01,  5.9537e-01,\n",
      "         -9.6076e-01,  1.0511e+00,  2.6099e+00, -8.3234e-01, -1.2075e-01,\n",
      "          3.9893e-01, -2.1066e-02]], device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class_embedding = model.get_text_features(caption_tokenized.to('cuda'))\n",
    "print(class_embedding.shape)\n",
    "print(class_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 512])\n",
      "tensor([[ 0.3634, -0.0956,  0.2164,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [ 0.3634, -0.0956,  0.2164,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [ 0.3634, -0.0956,  0.2164,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        ...,\n",
      "        [ 0.3634, -0.0956,  0.2164,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [ 0.3634, -0.0956,  0.2164,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [ 0.3634, -0.0956,  0.2164,  ..., -0.1207,  0.3989, -0.0211]],\n",
      "       device='cuda:0', grad_fn=<ExpandBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class_embedding = class_embedding.expand(features.shape[0], -1)\n",
    "print(class_embedding.shape)\n",
    "print(class_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1024])\n",
      "tensor([[ 1.0409, -0.2451,  0.5526,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [-0.0942,  0.4125, -0.3865,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [ 1.0073, -0.3329,  0.7318,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        ...,\n",
      "        [-0.9931, -0.2816,  0.8778,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [ 0.1886, -0.9309,  0.2961,  ..., -0.1207,  0.3989, -0.0211],\n",
      "        [ 0.0955, -1.4433,  0.4554,  ..., -0.1207,  0.3989, -0.0211]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "multimodal_embeddings = torch.cat([features, class_embedding], dim=1)\n",
    "print(multimodal_embeddings.shape)\n",
    "print(multimodal_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2])\n",
      "tensor([[ -23.9402,   20.6330],\n",
      "        [ -88.0289,   84.6446],\n",
      "        [ -84.3488,   81.2620],\n",
      "        [ -76.2346,   71.3858],\n",
      "        [ -58.7587,   54.9962],\n",
      "        [ -88.1227,   85.3095],\n",
      "        [ -45.6891,   40.2724],\n",
      "        [ -61.4424,   57.1874],\n",
      "        [ -43.1788,   39.4497],\n",
      "        [ -52.4088,   49.1902],\n",
      "        [ -87.3254,   83.9368],\n",
      "        [ -76.2545,   72.1617],\n",
      "        [ -33.9653,   30.4254],\n",
      "        [ -94.4177,   90.6792],\n",
      "        [ -12.4889,    8.0885],\n",
      "        [ -82.1984,   78.1978],\n",
      "        [ -59.3414,   54.7147],\n",
      "        [ -86.5210,   82.3090],\n",
      "        [ -53.8556,   50.5758],\n",
      "        [ -65.6672,   61.2014],\n",
      "        [ -64.0128,   59.5802],\n",
      "        [ -72.6029,   68.4713],\n",
      "        [ -91.5395,   88.3638],\n",
      "        [ -40.8095,   37.5870],\n",
      "        [ -26.9941,   24.5121],\n",
      "        [ -32.9176,   30.4817],\n",
      "        [ -79.6010,   73.8596],\n",
      "        [-109.4450,  104.2042],\n",
      "        [ -66.2686,   63.2535],\n",
      "        [ -85.3565,   81.8252],\n",
      "        [ -44.1070,   41.0210],\n",
      "        [ -79.5076,   74.8588],\n",
      "        [ -39.1688,   35.2911],\n",
      "        [ -95.3264,   90.0642],\n",
      "        [ -65.8309,   63.1808],\n",
      "        [ -74.7176,   70.6927],\n",
      "        [ -76.3214,   72.8204],\n",
      "        [ -57.4515,   52.8745],\n",
      "        [ -84.4412,   79.3129],\n",
      "        [ -68.1289,   63.2118],\n",
      "        [ -55.0373,   52.5437],\n",
      "        [ -44.3898,   41.4712],\n",
      "        [ -59.4297,   56.0340],\n",
      "        [ -87.4608,   84.4258],\n",
      "        [ -86.2140,   83.5023],\n",
      "        [ -80.4632,   75.5983],\n",
      "        [ -87.9259,   82.5350],\n",
      "        [ -52.2660,   46.5118],\n",
      "        [ -57.0538,   54.4273],\n",
      "        [ -51.6762,   48.0169],\n",
      "        [ -45.0682,   42.1308],\n",
      "        [ -73.4603,   69.0528],\n",
      "        [ -79.5239,   74.7684],\n",
      "        [ -62.5071,   58.6334],\n",
      "        [ -85.2343,   81.2930],\n",
      "        [ -87.5381,   83.5393],\n",
      "        [ -82.1116,   78.0263],\n",
      "        [ -81.9054,   77.8018],\n",
      "        [ -69.5199,   64.6995],\n",
      "        [ -57.1750,   52.1764],\n",
      "        [ -62.2373,   57.8477],\n",
      "        [ -59.1672,   56.0355],\n",
      "        [ -67.9878,   65.6851],\n",
      "        [ -14.3789,   10.9095],\n",
      "        [ -68.3336,   62.4787],\n",
      "        [ -57.2616,   54.1610],\n",
      "        [ -80.0655,   75.7586],\n",
      "        [ -85.8362,   82.1685],\n",
      "        [ -72.9913,   70.2125],\n",
      "        [ -84.4620,   79.9156],\n",
      "        [ -43.8537,   41.9338],\n",
      "        [ -77.4526,   73.0759],\n",
      "        [ -86.6719,   82.1888],\n",
      "        [ -82.5199,   79.9475],\n",
      "        [ -26.1530,   21.0083],\n",
      "        [ -72.3001,   68.3233],\n",
      "        [ -52.3766,   49.4895],\n",
      "        [ -88.0966,   84.3301],\n",
      "        [ -63.0906,   58.2213],\n",
      "        [ -64.4947,   59.9694],\n",
      "        [ -96.6717,   91.5448],\n",
      "        [ -48.6835,   45.3561],\n",
      "        [ -82.2951,   78.6770],\n",
      "        [ -70.4810,   65.7150],\n",
      "        [ -58.4387,   53.4507],\n",
      "        [ -55.4864,   52.4124],\n",
      "        [ -71.9947,   69.4174],\n",
      "        [ -15.2405,   11.8856],\n",
      "        [ -59.3354,   56.8324],\n",
      "        [ -63.4812,   61.5588],\n",
      "        [ -82.4443,   78.7909],\n",
      "        [ -62.0667,   57.3963],\n",
      "        [ -76.6586,   72.1403],\n",
      "        [ -87.6565,   82.9315],\n",
      "        [ -63.5466,   60.9868],\n",
      "        [ -84.3190,   80.7574],\n",
      "        [ -83.9185,   80.4347],\n",
      "        [ -92.2920,   88.3443],\n",
      "        [ -90.5493,   87.3412],\n",
      "        [ -83.8023,   80.1019],\n",
      "        [ -27.5883,   23.7442],\n",
      "        [ -60.8687,   56.8827],\n",
      "        [ -72.8489,   68.9215],\n",
      "        [ -91.5240,   87.3444],\n",
      "        [ -59.4684,   55.2552],\n",
      "        [ -66.6608,   64.0585],\n",
      "        [ -78.7049,   73.1269],\n",
      "        [ -53.8430,   49.0925],\n",
      "        [ -77.9751,   73.3195],\n",
      "        [ -87.9317,   86.3586],\n",
      "        [ -78.7288,   74.7799],\n",
      "        [ -82.1081,   77.9235],\n",
      "        [ -83.6193,   80.0933],\n",
      "        [ -14.7361,   10.6757],\n",
      "        [ -74.9508,   70.4584],\n",
      "        [ -93.4664,   91.8439],\n",
      "        [ -85.7691,   80.8344],\n",
      "        [ -66.2627,   63.2472],\n",
      "        [ -37.1718,   34.0966],\n",
      "        [ -57.2385,   54.1809],\n",
      "        [ -68.6413,   65.9574],\n",
      "        [ -67.0295,   63.1010],\n",
      "        [ -49.0475,   43.8911],\n",
      "        [ -96.4854,   91.8192],\n",
      "        [ -70.6128,   66.0930],\n",
      "        [ -97.5552,   91.8578],\n",
      "        [ -73.6487,   69.7442],\n",
      "        [ -49.1274,   44.9946]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = itm_head(multimodal_embeddings)\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0],\n",
      "        [12],\n",
      "        [14],\n",
      "        [87]])\n"
     ]
    }
   ],
   "source": [
    "where_class = targets == 33\n",
    "print(where_class.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([-12.4889, -14.3789, -14.7361, -15.2405, -23.9402], device='cuda:0',\n",
      "       grad_fn=<TopkBackward0>),\n",
      "indices=tensor([ 14,  63, 113,  87,   0], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(torch.topk(logits[:, 0], k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/5 output logits of neuron 0 (\"match\" neuron) with highest values are for matching image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "tensor([[[[-0.6706, -0.6549, -0.6392,  ...,  0.2000,  0.2157,  0.2314],\n",
      "          [-0.6627, -0.6392, -0.6235,  ...,  0.1843,  0.1843,  0.2000],\n",
      "          [-0.6549, -0.6314, -0.6157,  ...,  0.1922,  0.2157,  0.2235],\n",
      "          ...,\n",
      "          [-0.7490, -0.6941, -0.6941,  ..., -0.4980, -0.5373, -0.4588],\n",
      "          [-0.7569, -0.6784, -0.7098,  ..., -0.5373, -0.6157, -0.5529],\n",
      "          [-0.6784, -0.7490, -0.6784,  ..., -0.5059, -0.6627, -0.6314]],\n",
      "\n",
      "         [[-0.4980, -0.4824, -0.4667,  ..., -0.0745, -0.0745, -0.0745],\n",
      "          [-0.4902, -0.4667, -0.4510,  ..., -0.0824, -0.0902, -0.0902],\n",
      "          [-0.4824, -0.4588, -0.4431,  ..., -0.0353, -0.0431, -0.0353],\n",
      "          ...,\n",
      "          [-0.6784, -0.6235, -0.6235,  ..., -0.3412, -0.3961, -0.3333],\n",
      "          [-0.6863, -0.6078, -0.6392,  ..., -0.3882, -0.4745, -0.4275],\n",
      "          [-0.6078, -0.6784, -0.6078,  ..., -0.3569, -0.5137, -0.4824]],\n",
      "\n",
      "         [[-0.0431, -0.0275, -0.0118,  ..., -0.3098, -0.3490, -0.3725],\n",
      "          [-0.0353, -0.0118,  0.0039,  ..., -0.2941, -0.3412, -0.3647],\n",
      "          [-0.0275, -0.0039,  0.0118,  ..., -0.2078, -0.2471, -0.2706],\n",
      "          ...,\n",
      "          [-0.2314, -0.1765, -0.1765,  ...,  0.1059,  0.0588,  0.1294],\n",
      "          [-0.2392, -0.1608, -0.1922,  ...,  0.0667, -0.0196,  0.0353],\n",
      "          [-0.1608, -0.2392, -0.1765,  ...,  0.0980, -0.0588, -0.0275]]],\n",
      "\n",
      "\n",
      "        [[[-0.9843, -1.0000, -1.0000,  ..., -0.9765, -0.9608, -1.0000],\n",
      "          [-0.9608, -0.9922, -1.0000,  ..., -0.9843, -0.9765, -1.0000],\n",
      "          [-0.9294, -0.9843, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-0.9529, -0.9686, -0.9686,  ..., -1.0000, -0.9765, -0.9294],\n",
      "          [-0.9451, -0.9608, -0.9765,  ..., -0.9765, -0.9843, -0.9686],\n",
      "          [-0.9451, -0.9608, -0.9843,  ..., -0.9608, -0.9843, -0.9922]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -0.9451, -0.9373, -0.9843],\n",
      "          [-0.9843, -1.0000, -1.0000,  ..., -0.9608, -0.9608, -0.9843],\n",
      "          [-0.9529, -0.9922, -1.0000,  ..., -0.9922, -0.9922, -0.9922],\n",
      "          ...,\n",
      "          [-0.9686, -0.9686, -0.9608,  ..., -0.9922, -0.9922, -0.9451],\n",
      "          [-0.9608, -0.9686, -0.9686,  ..., -0.9686, -1.0000, -0.9765],\n",
      "          [-0.9608, -0.9686, -0.9765,  ..., -0.9608, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.8196, -0.8510, -0.8824,  ..., -0.9216, -0.9137, -0.9608],\n",
      "          [-0.8118, -0.8588, -0.8902,  ..., -0.9373, -0.9373, -0.9608],\n",
      "          [-0.7882, -0.8667, -0.9137,  ..., -0.9686, -0.9686, -0.9686],\n",
      "          ...,\n",
      "          [-0.9451, -0.9765, -0.9922,  ..., -0.9922, -0.9608, -0.8980],\n",
      "          [-0.9373, -0.9765, -0.9922,  ..., -0.9843, -0.9686, -0.9373],\n",
      "          [-0.9373, -0.9765, -0.9922,  ..., -0.9765, -0.9765, -0.9608]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6784,  0.6392,  0.6392,  ...,  0.6471,  0.6627,  0.6706],\n",
      "          [ 0.6392,  0.5843,  0.5843,  ...,  0.5843,  0.6157,  0.6314],\n",
      "          [ 0.6078,  0.5451,  0.5294,  ...,  0.5216,  0.5608,  0.6000],\n",
      "          ...,\n",
      "          [ 0.6392,  0.5608,  0.5373,  ...,  0.5059,  0.5451,  0.5843],\n",
      "          [ 0.6235,  0.5529,  0.5765,  ...,  0.5608,  0.5765,  0.5922],\n",
      "          [ 0.6706,  0.6157,  0.6392,  ...,  0.5922,  0.6000,  0.6157]],\n",
      "\n",
      "         [[ 0.4902,  0.4588,  0.4667,  ...,  0.4431,  0.4588,  0.4667],\n",
      "          [ 0.4510,  0.4118,  0.4118,  ...,  0.3961,  0.4196,  0.4275],\n",
      "          [ 0.4275,  0.3725,  0.3647,  ...,  0.3490,  0.3804,  0.4118],\n",
      "          ...,\n",
      "          [ 0.4353,  0.3647,  0.3490,  ...,  0.3490,  0.3882,  0.4353],\n",
      "          [ 0.4275,  0.3725,  0.4039,  ...,  0.3961,  0.4118,  0.4353],\n",
      "          [ 0.4980,  0.4431,  0.4667,  ...,  0.4196,  0.4275,  0.4431]],\n",
      "\n",
      "         [[ 0.0196, -0.0039,  0.0196,  ..., -0.0196,  0.0039,  0.0196],\n",
      "          [-0.0196, -0.0510, -0.0353,  ..., -0.0745, -0.0431, -0.0196],\n",
      "          [-0.0275, -0.0824, -0.0824,  ..., -0.1059, -0.0745, -0.0431],\n",
      "          ...,\n",
      "          [-0.0118, -0.0824, -0.0745,  ..., -0.0745, -0.0588, -0.0196],\n",
      "          [-0.0196, -0.0745, -0.0431,  ..., -0.0510, -0.0431, -0.0275],\n",
      "          [ 0.0431, -0.0118,  0.0118,  ..., -0.0353, -0.0275, -0.0118]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.8510,  0.8667,  0.8824,  ...,  0.8588,  0.8588,  0.8745],\n",
      "          [ 0.8510,  0.8667,  0.8824,  ...,  0.8745,  0.8745,  0.8902],\n",
      "          [ 0.8588,  0.8667,  0.8745,  ...,  0.8902,  0.8902,  0.8902],\n",
      "          ...,\n",
      "          [-0.3255, -0.3255, -0.3412,  ...,  0.2157,  0.2157,  0.2157],\n",
      "          [-0.3961, -0.3882, -0.3725,  ...,  0.2157,  0.2157,  0.2157],\n",
      "          [-0.5765, -0.5529, -0.5216,  ...,  0.2157,  0.2157,  0.2078]],\n",
      "\n",
      "         [[-0.2627, -0.2471, -0.2314,  ..., -0.2627, -0.2627, -0.2471],\n",
      "          [-0.2627, -0.2471, -0.2314,  ..., -0.2471, -0.2471, -0.2314],\n",
      "          [-0.2549, -0.2471, -0.2392,  ..., -0.2314, -0.2314, -0.2314],\n",
      "          ...,\n",
      "          [-0.5922, -0.6078, -0.6235,  ..., -0.7725, -0.7725, -0.7725],\n",
      "          [-0.6157, -0.6157, -0.6078,  ..., -0.7725, -0.7725, -0.7725],\n",
      "          [-0.7725, -0.7647, -0.7333,  ..., -0.7569, -0.7569, -0.7647]],\n",
      "\n",
      "         [[-0.1686, -0.1529, -0.1373,  ..., -0.1059, -0.1059, -0.0902],\n",
      "          [-0.1686, -0.1529, -0.1373,  ..., -0.0902, -0.0902, -0.0745],\n",
      "          [-0.1608, -0.1529, -0.1451,  ..., -0.0745, -0.0745, -0.0745],\n",
      "          ...,\n",
      "          [-0.7333, -0.7490, -0.7725,  ..., -0.6784, -0.6784, -0.6784],\n",
      "          [-0.7098, -0.7098, -0.7098,  ..., -0.6784, -0.6784, -0.6784],\n",
      "          [-0.8353, -0.8275, -0.8118,  ..., -0.6706, -0.6706, -0.6784]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]]])\n",
      "torch.Size([16])\n",
      "tensor([94,  2, 23,  1,  5, 48,  3, 71, 56, 30,  3, 51, 35, 45,  5,  3])\n"
     ]
    }
   ],
   "source": [
    "loader_caltech101 = dataloaders['Caltech101']['test']\n",
    "batch = next(iter(loader_caltech101))\n",
    "inputs, targets = batch\n",
    "print(inputs.shape)\n",
    "print(inputs)\n",
    "print(targets.shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "tensor([ 0.4966, -1.1076,  0.9623,  0.0328, -0.4631,  0.3592, -0.0867,  0.6580,\n",
      "        -0.8098, -1.1734,  0.8335, -0.1524,  0.3226, -0.0650,  1.4281,  0.7274,\n",
      "         1.3255,  1.4866,  0.4209, -0.3393, -0.9781,  0.2292,  0.4155,  0.6341,\n",
      "        -0.1248,  0.7073,  0.4461,  0.4796,  1.7555,  0.6825, -1.4581, -0.6464,\n",
      "         0.4240, -0.3164,  1.0878, -1.0156,  0.3479, -0.6284, -0.1435,  0.1391,\n",
      "         0.4610,  0.5195, -0.6118, -0.9204, -1.8489,  0.6457,  1.0072,  0.5921,\n",
      "         0.0798, -0.8742, -1.0587,  0.8590,  0.9960,  0.8942,  0.0062,  1.0705,\n",
      "         0.6953, -0.5197, -0.7388,  0.7114, -0.2361,  0.0095,  0.6026,  0.7467,\n",
      "        -0.0192,  0.4475, -0.4838,  0.4995,  0.3281,  0.3353, -0.5249, -0.0338,\n",
      "         0.7304, -0.3361,  0.2528, -0.5073,  0.6438,  0.0041, -0.5131, -1.8558,\n",
      "         0.0117,  0.1525, -0.4858, -0.9868, -0.5843,  1.4586,  0.5246, -0.4996,\n",
      "         0.2811, -0.6550,  0.1762,  0.3072,  1.1519, -0.1377,  0.0911,  0.3932,\n",
      "         0.4592, -0.2076,  0.5863, -1.4602,  0.3592,  0.1775,  0.2822,  0.7879,\n",
      "         0.1548, -0.5876,  0.2673, -0.6245,  0.0629, -1.0065,  0.1920,  1.9274,\n",
      "        -0.2834,  0.1400, -0.5994, -0.6052, -0.2890,  0.2994,  1.0165, -0.0866,\n",
      "         0.6727,  0.0943, -0.9598, -0.9279,  0.2279, -0.4486,  1.0916,  0.4029,\n",
      "         1.5599, -1.7639,  0.1527, -1.6308,  0.7200, -2.1774,  0.5988,  0.1195,\n",
      "         0.1287,  0.2902,  0.4959, -0.1076,  0.4845,  0.0505,  0.5491, -0.3279,\n",
      "         0.4180, -0.6320,  0.2949, -0.8253,  1.1323,  0.1102,  0.9439, -0.3969,\n",
      "        -0.3622, -1.2585,  1.0256, -0.3194, -0.3379,  0.8367,  0.5555,  0.3216,\n",
      "        -0.0855,  1.9235,  0.3218,  1.0305, -0.3647, -0.7420, -0.3813,  0.0037,\n",
      "         0.8980,  0.9890,  1.2763, -1.2447,  0.3833,  0.4849,  0.3467, -0.4057,\n",
      "         0.2980,  0.3833,  1.4522, -0.2056, -0.0909, -0.0459,  0.7244,  0.5412,\n",
      "        -0.9288, -0.1898, -1.3198, -0.3905, -0.3116,  0.3329,  0.5687, -0.5309,\n",
      "         0.8445,  0.3880,  0.3949,  0.5128, -0.0078, -0.6524, -1.1755, -0.4174,\n",
      "        -0.7033,  0.6954,  1.5795,  0.4854, -1.1941, -0.8206, -0.0623, -0.0178,\n",
      "        -1.2124, -0.2681, -0.1516,  0.1090,  0.4509,  0.2422,  1.0439,  0.9704,\n",
      "         0.7462,  0.7936,  0.6721, -0.8125,  1.2324,  1.5882, -1.6826,  1.6173,\n",
      "        -1.4223,  0.3679,  1.6084,  0.3776, -0.5408, -0.6680,  0.4799, -0.8279,\n",
      "         0.1002, -1.4588,  1.4492, -0.0550, -0.3823,  0.3976, -0.6985,  0.0985,\n",
      "         0.0414,  0.2672, -0.1991,  0.8707, -0.7511, -0.7433,  0.1973, -1.5712,\n",
      "        -0.3521,  0.2223,  1.7306,  1.7995, -0.3473, -0.1715, -0.2208,  0.2742,\n",
      "         0.4266, -0.6109, -0.6751,  1.0031,  0.0037,  0.8189, -0.4401, -0.2579,\n",
      "         0.2191, -0.9700, -0.0913,  0.1612, -0.6532,  0.4526,  0.8749,  0.1689,\n",
      "         0.2015,  0.1246, -0.4977,  0.2908, -0.2368,  1.3700,  0.5204, -1.5753,\n",
      "         1.0904, -0.9291,  0.0913,  0.3418, -0.6048, -0.2045, -0.4700,  0.8244,\n",
      "        -1.2750, -1.8393,  0.6469,  0.1338,  0.1747,  0.1055, -0.7844, -0.3272,\n",
      "        -0.2332, -1.4435, -0.1886,  0.6760, -1.1372, -0.4142,  0.7179, -1.4911,\n",
      "        -0.1945,  0.9260,  0.5308, -0.7799,  0.8387, -0.8666,  0.9376,  1.2597,\n",
      "         0.0575, -0.6141,  0.3113,  0.2820,  1.0428, -1.2317, -0.9485, -0.9302,\n",
      "         0.7808, -2.1426, -0.7509,  0.0317,  0.4146,  0.5708,  0.2241,  0.5727,\n",
      "         0.4251,  0.7429,  0.8200, -0.2653, -0.0838,  1.4184, -0.6404,  1.1834,\n",
      "         0.1479,  1.6339,  0.2053, -0.4428, -0.4340,  0.2955, -1.4667,  0.0456,\n",
      "        -0.2899, -1.1193,  0.0144,  0.0815,  0.8870, -0.4686,  0.7786, -1.3404,\n",
      "         0.7322, -0.7991,  0.7615,  0.5526,  1.1218, -0.4945,  0.2463,  0.2481,\n",
      "         0.3299, -0.6244,  2.1412, -0.5599, -0.3638, -0.9668, -0.2801, -0.2795,\n",
      "         0.3086, -0.3146,  0.5845, -0.3566,  0.1822,  0.9245,  0.2789, -0.8248,\n",
      "         0.3926, -0.9766,  0.7271,  1.2951, -0.9962, -0.4325,  0.6901, -0.1791,\n",
      "         0.8721, -0.7243, -1.2809, -0.0133, -0.5594,  0.1871,  0.7416, -0.0497,\n",
      "         0.1759, -0.2463,  0.2048, -0.4272,  0.9963,  0.3252,  0.4063, -0.8937,\n",
      "        -0.6691, -0.0363,  1.7258, -0.7851, -1.9032, -1.1419, -0.9556, -0.7915,\n",
      "         0.0236, -0.5550,  0.8692,  0.4979, -0.0484, -0.1577,  0.0090, -0.8668,\n",
      "         0.0796,  0.5058,  1.4103,  0.6187, -0.2924,  0.7820,  0.5049, -0.7717,\n",
      "         1.3993, -1.1660, -0.7978,  1.1090, -1.0088,  0.0196,  0.0704, -0.1080,\n",
      "        -0.2838, -0.7910,  0.4110, -0.5689, -1.3367, -0.6667,  1.1319, -0.3284,\n",
      "        -0.2590,  1.4055,  0.4511,  0.3264,  0.5865,  0.7773, -0.0985, -0.2208,\n",
      "         0.2178,  1.0117,  0.4615,  0.2979, -0.7184, -0.3663,  0.0456,  0.7956,\n",
      "        -0.0144,  0.4523, -1.1443,  0.1453,  1.0732,  0.2626, -0.4308,  0.3548,\n",
      "         1.6453, -0.0536,  0.8008,  0.1369,  0.7216,  0.3673,  0.4899, -0.1146,\n",
      "         0.7603,  0.1487, -0.0022,  1.0346,  0.1211,  0.0569,  0.7163, -0.7430,\n",
      "        -0.4531,  0.6316, -0.6270, -0.5319, -0.3209, -1.2308,  1.6108,  0.2181,\n",
      "         0.0982, -0.5225,  0.5635, -0.9251,  0.2499, -0.2064, -0.8533,  0.2794,\n",
      "        -0.1876,  0.5706, -0.2944, -1.7687,  0.7399,  0.6890, -0.2664, -0.1974,\n",
      "         0.9655, -1.0810,  1.1621, -0.1802, -0.6456, -0.5224, -0.8284,  0.3881],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(94)\n"
     ]
    }
   ],
   "source": [
    "feature = model.get_image_features(inputs.to('cuda'))[0]\n",
    "print(feature.shape)\n",
    "print(feature)\n",
    "target = targets[0]\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tick', 'trilobite', 'umbrella', 'watch', 'water lilly', 'wheelchair']\n"
     ]
    }
   ],
   "source": [
    "classnames = loader_caltech101.dataset.classnames\n",
    "classname_selection = classnames[target-3:target+3]\n",
    "print(classname_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a photo of a tick.', 'a photo of a trilobite.', 'a photo of a umbrella.', 'a photo of a watch.', 'a photo of a water lilly.', 'a photo of a wheelchair.']\n"
     ]
    }
   ],
   "source": [
    "template = \"a photo of a {}.\"\n",
    "captions = [template.format(x) for x in classname_selection]\n",
    "print(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1037,  6302,  1997,  1037, 16356,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101,  1037,  6302,  1997,  1037, 13012,  4135, 16313,  2063,  1012,\n",
      "           102],\n",
      "        [  101,  1037,  6302,  1997,  1037, 12977,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101,  1037,  6302,  1997,  1037,  3422,  1012,   102,     0,     0,\n",
      "             0],\n",
      "        [  101,  1037,  6302,  1997,  1037,  2300, 14765,  1012,   102,     0,\n",
      "             0],\n",
      "        [  101,  1037,  6302,  1997,  1037, 13204,  1012,   102,     0,     0,\n",
      "             0]])\n",
      "torch.Size([6, 512])\n",
      "tensor([[ 0.6263,  0.5572,  1.4229,  ...,  0.9261, -0.4038,  0.4696],\n",
      "        [-0.1852,  0.1725,  1.2424,  ..., -0.1371, -1.1789, -0.7680],\n",
      "        [ 0.2672, -0.2301,  2.2116,  ..., -0.6446, -0.3870, -0.8674],\n",
      "        [ 0.3341,  0.3266,  0.7137,  ..., -0.0503, -0.2253, -0.1699],\n",
      "        [ 0.0716,  0.1309,  1.6009,  ..., -0.0593, -0.4861, -0.9418],\n",
      "        [ 0.3156,  0.5962,  1.3438,  ..., -0.4822, -0.5651, -1.3828]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "caption_tokenized = processor(text=captions, padding=True, truncation=True, return_tensors=\"pt\")['input_ids']\n",
    "print(caption_tokenized)\n",
    "class_embedding = model.get_text_features(caption_tokenized.to('cuda'))\n",
    "print(class_embedding.shape)\n",
    "print(class_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 512])\n",
      "tensor([[ 0.4966, -1.1076,  0.9623,  ..., -0.5224, -0.8284,  0.3881],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.5224, -0.8284,  0.3881],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.5224, -0.8284,  0.3881],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.5224, -0.8284,  0.3881],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.5224, -0.8284,  0.3881],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.5224, -0.8284,  0.3881]],\n",
      "       device='cuda:0', grad_fn=<ExpandBackward0>)\n"
     ]
    }
   ],
   "source": [
    "feature = feature.expand(class_embedding.shape[0], -1)\n",
    "print(feature.shape)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1024])\n",
      "tensor([[ 0.4966, -1.1076,  0.9623,  ...,  0.9261, -0.4038,  0.4696],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.1371, -1.1789, -0.7680],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.6446, -0.3870, -0.8674],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.0503, -0.2253, -0.1699],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.0593, -0.4861, -0.9418],\n",
      "        [ 0.4966, -1.1076,  0.9623,  ..., -0.4822, -0.5651, -1.3828]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "multimodal_embeddings = torch.cat([feature, class_embedding], dim=1)\n",
    "print(multimodal_embeddings.shape)\n",
    "print(multimodal_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "tensor([[-63.8308,  58.4294],\n",
      "        [-48.5656,  45.5814],\n",
      "        [-53.5590,  48.5309],\n",
      "        [-19.3385,  13.9102],\n",
      "        [-63.9262,  59.6700],\n",
      "        [-43.9359,  36.5553]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = itm_head(multimodal_embeddings)\n",
    "print(logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_class = targets == 94\n",
    "print(where_class.nonzero())\n",
    "print(torch.topk(logits[:, 0], k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct image/label embedding has highest logit value in neuron 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
