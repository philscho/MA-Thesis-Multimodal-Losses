{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5fc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "rootutils.setup_root('.', indicator=\".project-root\", pythonpath=True)\n",
    "from src.model.model_module import LitMML\n",
    "from src.model.utils import get_model_and_processor\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1577be87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phisch/venv_py3.8/py3.8/lib/python3.8/site-packages/lightning/pytorch/utilities/migration/utils.py:56: The loaded checkpoint was produced with Lightning v2.2.3, which is newer than your current Lightning version: v2.2.0.post0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = '/home/data/bhavin/ckpts/93t3xgrr/last.ckpt' # CLIP+ITM\n",
    "model, processor = get_model_and_processor(config=OmegaConf.load('../configs/model/dual_encoder.yaml'))\n",
    "lit_model = LitMML.load_from_checkpoint(ckpt_path, model=model, processor=processor, map_location=device)\n",
    "model, processor = lit_model.model, lit_model.processor\n",
    "itm_head = lit_model.itm_head\n",
    "print(itm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5cbfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Caltech101': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f404c45c430>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f3ee43f5700>}}\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_module import MyDataModule\n",
    "data_config = OmegaConf.load('../configs/data/test.yaml')\n",
    "data_config.root = '/home/data'\n",
    "data_config.dataloader.test.batch_size = 16\n",
    "data_config.datasets = [\"Caltech101\"]\n",
    "data_module = MyDataModule(data_config=data_config, processor=processor)\n",
    "dataloaders = data_module.get_test_dataloaders()\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e28085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifier weights...: 100%|██████████| 7/7 [00:02<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.callbacks.zeroshot_callback import (\n",
    "    _create_zero_shot_classifier, \n",
    "    _evaluate_zero_shot,\n",
    "    _get_itm_head_predictions\n",
    ")\n",
    "\n",
    "loader = dataloaders[\"Caltech101\"][\"test\"]\n",
    "class_names = loader.dataset.classnames\n",
    "num_classes = len(class_names)\n",
    "templates = [\"a photo of a {}.\"]\n",
    "verbose = True\n",
    "dtype = torch.float32\n",
    "forward_func = lambda x: model.get_image_features(pixel_values=x)\n",
    "top_k_preds = 10\n",
    "\n",
    "classifier = _create_zero_shot_classifier(\n",
    "    forward_func=lambda x, y: model.get_text_features(input_ids=x, attention_mask=y),\n",
    "    classnames=class_names,\n",
    "    templates=templates,\n",
    "    tokenizer=processor,\n",
    "    batch_size=loader.batch_size,\n",
    "    device=device,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...:   0%|          | 0/109 [00:00<?, ?it/s]ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    # MultilabelAveragePrecision,\n",
    "    # MulticlassConfusionMatrix,\n",
    ")\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "top_k = [1, 5, 10]\n",
    "metric_kwargs = dict(dist_sync_on_step=False, sync_on_compute=False)\n",
    "metric = {\n",
    "            f'Top{k}Accuracy': MulticlassAccuracy(top_k=k, average=\"micro\", num_classes=num_classes, **metric_kwargs)\n",
    "            for k in top_k\n",
    "        }\n",
    "metric = MetricCollection(metric).to(device)\n",
    "metric_itm = MetricCollection({k: v.clone() for k, v in metric.items()}).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    bar = tqdm(loader, desc=f'Predicting...', total=len(loader)) if verbose else loader\n",
    "    for point in bar:\n",
    "        inputs, target = point\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=True, dtype=dtype):\n",
    "            features = forward_func(inputs)\n",
    "        features /= features.norm(dim=-1, keepdim=True)\n",
    "        logits_regular = features @ classifier\n",
    "        step_metric = metric(logits_regular, target.squeeze().long())\n",
    "        if itm_head:\n",
    "            logits_itm = _get_itm_head_predictions(itm_head, logits_regular.clone(), top_k_preds, features, classifier)\n",
    "            step_metric_itm = metric_itm(logits_itm, target.squeeze().long())\n",
    "        if verbose:\n",
    "            postfix = {f\"{k}\": v.item() for k, v in step_metric.items() if k != 'ConfusionMatrix'}\n",
    "            if itm_head:\n",
    "                postfix.update({f\"itm_{k}\": v.item() for k, v in step_metric_itm.items() if k != 'ConfusionMatrix'})\n",
    "            bar.set_postfix(postfix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
