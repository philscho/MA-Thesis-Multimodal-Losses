save_dir: './models/cliplike/'
#resume_checkpoint: '/home/phisch/multimodal/models/cliplike/ckpts/5m917c9w/last.ckpt'

wandb:
  tags :
    #- 'itm: binary cross-entropy'
    - 'clip'
    - 'itm'
    - 'simclr'
  offline: ${lightning.trainer.fast_dev_run}
  #name: 
  #group: 'debug'
  #group: 'test'
  group: 'run'
  entity: 'arena-multimodal-lossfns'
  project : 'multimodal'
  dir : './wandb/'
  ### checkpoint args
  #id: 5m917c9w

lightning:
  seed: 69
  trainer:
    fast_dev_run: False #True #False
    #overfit_batches: 1
    val_check_interval: 0.3
    log_every_n_steps: 1 #5 #10
    max_epochs: 150
    devices: [0, 1]  #[01] #[3] #[0 1]
    num_nodes: 1
    #========================#
    accelerator: 'gpu'
    strategy: 'ddp' #'ddp_find_unused_parameters_true'
    deterministic: 'warn' #True
    precision: '16-mixed'
    gradient_clip_algorithm: "norm"
    gradient_clip_val: 1.0   
    static_graph: True #False #True #False #True
  model_checkpoint_callback:
    every_n_epochs: 1
    save_last: True
    save_top_k: 2
gradient_checkpointing: True

loss:
  losses:
    - 'contrastive'
    - 'image_text_matching'
    - 'SimCLR'
  contrastive:
  #  temperature : 1.
  image_text_matching:
    arg1: ''

optimizer:
  name : "AdamW"
  lr: 2e-05
  kwargs:
    weight_decay : 0.1
    betas : [0.9, 0.95]

scheduler:
  enabled: True
  name: CosineWarmup
  monitor: 'loss-val'
  interval: 'step'
  kwargs:
    initial_lr: 1e-08
    num_warmup_steps: 'epoch'
    num_training_steps: 'all'

dataloader:
  train:
    shuffle : True
    batch_size : 64 #512 #1024 #512 #1792 #1920 #2048 #256 #512 #1536 #2048  #896 #960 #1024 #256 #180
    #batch_size : 192
    num_workers: 8
    persistent_workers: True
    pin_memory: True

  coco_val:
    shuffle : False
    #batch_size : 
    batch_size : 64 #512 #1024 #512 #1792 #1024 #1920 #2048 #256 #512 #1536 #896 #960 #1024 #256 #180
    num_workers : 8
    #persistent_workers: True
    pin_memory: True
  
  cifar10_val:
    batch_size: 1024 #512
    shuffle: False
    num_workers: 8
    #persistent_workers: True
    pin_memory: True

  caltech101_val:
    batch_size: 1024
    shuffle: False
    num_workers: 8
    #persistent_workers: True
    pin_memory: True

model:
  #image_encoder_name : 'openai/clip-vit-base-patch32'
  #text_encoder_name : 'openai/clip-vit-base-patch32'
  image_encoder_name : 'google/vit-base-patch16-224'
  text_encoder_name : 'google-bert/bert-base-uncased'
  tokenizer :
    use_fast: False

dataset:
  train:
    - 'coco'
    - 'vg'
    - 'cc3m'
  val:
    - 'coco_val'
    - 'cifar10'
    - 'caltech101'
  transforms: 
    enabled: True #False #True
    RandAugment:
      num_ops: 3
      magnitude: 8
  max_seq_length: 72
  coco:
    root: '/home/data/COCOcaptions/'
  vg:
    data_dir: '/pfss/mlde/workspaces/mlde_wsp_PI_Roig/shared/datasets/VG_Bhavin/VG'
  cc3m:
    data_dir: '/pfss/mlde/workspaces/mlde_wsp_PI_Roig/shared/datasets/CC3m/h5'
  cifar10:
    root: '/home/phisch/data/cifar-10-batches-py'
    download: false
  caltech101 :
    root: '/pfss/mlde/workspaces/mlde_wsp_PI_Roig/shared/datasets/cifar10'
    download: false
  use_subset:
    value: true
    subset_fraction: 0.2
  use_subset_probe:
    value: false
    subset_fraction: 0.2
  cateogries:
    cifar10:
      - 'airplane'
      - 'automobile'
      - 'bird'
      - 'cat'
      - 'deer'
      - 'dog'
      - 'frog'
      - 'horse'
      - 'ship'
      - 'truck'
    caltech101:
      - 'face'
      - 'leopard'
      - 'motorbike'
      - 'accordion'
      - 'airplane'
      - 'anchor'
      - 'ant'
      - 'barrel'
      - 'bass'
      - 'beaver'
      - 'binocular'
      - 'bonsai'
      - 'brain'
      - 'brontosaurus'
      - 'buddha'
      - 'butterfly'
      - 'camera'
      - 'cannon'
      - 'car side'
      - 'ceiling fan'
      - 'cellphone'
      - 'chair'
      - 'chandelier'
      - 'body of a cougar'
      - 'face of a cougar'
      - 'crab'
      - 'crayfish'
      - 'crocodile'
      - 'crocodile head'
      - 'cup'
      - 'dalmatian'
      - 'dollar bill'
      - 'dolphin'
      - 'dragonfly'
      - 'electric guitar'
      - 'elephant'
      - 'emu'
      - 'euphonium'
      - 'ewer'
      - 'ferry'
      - 'flamingo'
      - 'flamingo head'
      - 'garfield'
      - 'gerenuk'
      - 'gramophone'
      - 'grand piano'
      - 'hawksbill'
      - 'headphone'
      - 'hedgehog'
      - 'helicopter'
      - 'ibis'
      - 'inline skates'
      - 'joshua tree'
      - 'kangaroo'
      - 'ketch'
      - 'lamp'
      - 'laptop'
      - 'llama'
      - 'lobster'
      - 'lotus'
      - 'mandolin'
      - 'mayfly'
      - 'menorah'
      - 'metronome'
      - 'minaret'
      - 'nautilus'
      - 'octopus'
      - 'okapi'
      - 'pagoda'
      - 'panda'
      - 'pigeon'
      - 'pizza'
      - 'platypus'
      - 'pyramid'
      - 'revolver'
      - 'rhino'
      - 'rooster'
      - 'saxophone'
      - 'schooner'
      - 'scissors'
      - 'scorpion'
      - 'sea horse'
      - 'snoopy'
      - 'soccer ball'
      - 'stapler'
      - 'starfish'
      - 'stegosaurus'
      - 'stop sign'
      - 'strawberry'
      - 'sunflower'
      - 'tick'
      - 'trilobite'
      - 'umbrella'
      - 'watch'
      - 'water lilly'
      - 'wheelchair'
      - 'wild cat'
      - 'windsor chair'
      - 'wrench'
      - 'yin yang'
    

zeroshot:
  templates:
    - 'a photo of a {}.'
    - 'a blurry photo of a {}.'
    - 'a black and white photo of a {}.'
    - 'a low contrast photo of a {}.'
    - 'a high contrast photo of a {}.'
    - 'a bad photo of a {}.'
    - 'a good photo of a {}.'
    - 'a photo of a small {}.'
    - 'a photo of a big {}.'
    - 'a photo of the {}.'
    - 'a blurry photo of the {}.'
    - 'a black and white photo of the {}.'
    - 'a low contrast photo of the {}.'
    - 'a high contrast photo of the {}.'
    - 'a bad photo of the {}.'
    - 'a good photo of the {}.'
    - 'a photo of the small {}.'
    - 'a photo of the big {}.'


# scheduler:
#   name: SequentialLR
#   kwargs: 
#     milestones: [2]
#   sub_schedulers:
#     - name: 'ReduceROnPlateau'
#       kwargs:
#         num_warmup_steps: 'epoch'
#     - name: 'CosineWarmupHardRestarts'
#       kwargs:
#             T_max: 1000

# scheduler:
#   name:
#     - 'CosineWarmup'
#     #- 'CosineWarmupHardRestarts'
#   kwargs:
#     #T_max : 1000
#     num_warmup_steps: 'epoch'
#     num_training_steps: 'all' #20000
#     #num_cycles: 10
#     initial_lr: 1e-08
#   interval: "step"

# scheduler:
#   name: SequentialLR
#   monitor: 'loss-val/dataloader_idx_0'
#   interval: 'step'
#   kwargs: 
#     milestones: [100]
#   sub_schedulers:
#     - name: 'CosineAnnealingWarmRestarts'
#       kwargs:
#         T_0: 100
#     - name: 'ExponentialLR'
#       kwargs:
#         gamma: 0.95
#         verbose: true

# scheduler:
#   name: CyclicLR
#   monitor: 'loss-val/dataloader_idx_0'
#   interval: 'step'
#   kwargs:
#     base_lr: 0.0003
#     max_lr: 0.0004

# scheduler:
#   name: OneCycleLR
#   monitor: 'loss-val/dataloader_idx_0'
#   interval: 'step'
#   kwargs:
#     max_lr: 0.004
#     steps_per_epoch: 121
#     epochs: 40